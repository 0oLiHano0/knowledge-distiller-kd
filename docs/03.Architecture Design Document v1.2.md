**1. 概述 (Overview)**

- **1.1 设计目标:** 本文档旨在描述知识蒸馏器 (KD_tool) 项目**当前已重构完成并持续演进的系统架构**，明确各组件职责、交互方式和技术选型。本文档亦作为指导后续阶段（特别是Phase 3: PDF支持与用户交互）开发的技术蓝图。项目核心目标是构建一款本地化运行的源信息治理工具，通过去重等手段提升下游知识应用（PKB, RAG）的效率和质量。**强调：本工具非知识库或问答系统。**
- **1.2 设计范围:** 本文档主要描述当前已实现的**分层架构**（UI-CLI, Engine, Analysis, Processing, Storage-FileStorage）及其核心功能（Markdown解析、代码块合并、MD5及基础语义去重、决策保存与应用）。同时，本文档也为下一阶段（Phase 3）的功能（如PDF支持、SQLite存储、GUI基础、用户审核交互）提供架构指导。**本文档已更新以反映存储层对按文件ID分离的多个JSON文件的管理、数据传输对象(DTO)的使用，以及对`BlockMerger`当前状态的精确说明。**
- **1.3 相关需求:** 本设计的需求来源于CTO提供的项目背景、痛点分析、分阶段目标及详细功能/非功能需求描述（见初始设定Prompt）。

**2. 设计原则与约束 (Guiding Principles & Constraints)**

- **2.1 核心原则:**
    - **本地化优先 (Local-First & Offline-Capable):** 核心功能和数据处理完全在本地进行。_(当前实现)_
    - **模块化与可维护性:** 采用分层架构，各层职责清晰，低耦合，便于独立开发、测试和维护。_(已通过重构实践)_
    - **分阶段演进:** 功能按计划分阶段实现，特别是对LLM等复杂技术采取谨慎、逐步引入的策略。
    - **用户为中心:** (未来GUI阶段) 需考虑非技术用户的易用性，提供清晰的结果展示和交互审核机制。
    - **性能与资源效率:** 优化本地计算和存储资源消耗。
- **2.2 主要约束:**
    - **部署模型:** 严格本地化桌面应用。
    - **数据隐私:** 最高级别，用户数据不离本地。
    - **LLM使用策略:** 遵循分阶段计划，**当前版本未使用LLM**。后续（Phase 4）仅考虑**本地、辅助型**LLM，结果需用户确认。
    - **技术栈限制:** (详见第4节)
    - **其他:** (参考初始设定Prompt中的约束列表，根据CTO输入更新)

**3. 系统架构 (System Architecture)**

- **3.1 高层架构图 (High-Level Diagram):**
    
    - 当前系统采用分层架构，将项目划分为以下几个逻辑层：
        
        1. **应用入口 (Application Entry Point):** 负责启动应用、解析命令行参数、组装核心组件。
        2. **用户界面层 (UI Layer):** 负责与用户交互，展示信息，接收命令。目前是 CLI，未来可以是 GUI 或 Web API。
        3. **核心引擎层 (Core Engine Layer):** 封装核心业务逻辑、状态管理和流程编排。是 UI 层与底层工具交互的桥梁。
        4. **分析工具层 (Analysis Layer):** 包含具体的分析算法实现（MD5、语义）。
        5. **处理工具层 (Processing Layer):** 包含文档解析、内容块合并等预处理逻辑。
        6. **存储层 (Storage Layer):** 抽象数据持久化逻辑，通过接口定义，当前具体实现为基于文件ID的多JSON文件存储，未来可以是数据库。
        
        逻辑关系如下：
```mermaid
graph LR;
    UserInput[用户输入/操作] --> CLILayer[UI层 CLI]
    CLILayer -- 调用 --> CoreEngineLayer[核心引擎层]

    CoreEngineLayer -- 调用进行处理 --> ProcessingLayer[处理层]
    ProcessingLayer -- 返回处理后数据 (DTOs) --> CoreEngineLayer

    CoreEngineLayer -- 调用进行分析 --> AnalysisLayer[分析层]
    AnalysisLayer -- 返回分析结果 --> CoreEngineLayer

    CoreEngineLayer -- 通过接口进行数据读写 (DTOs) <--> StorageInterface[存储接口]
    StorageInterface -- 由具体实现提供 --> FileStorage[存储层 FileStorage (按文件ID的JSONs)]

    CoreEngineLayer -- 更新UI数据/状态 --> CLILayer
    CLILayer -- 展示给用户 --> UserOutput[用户输出/结果]

    subgraph 应用入口 [Application Entry Point]
        EntryPoint[cli.py]
    end

    subgraph 用户界面层 [UI Layer]
        CLILayer
        %% Future GUI Layer %%
    end

    subgraph 核心逻辑层 [Core Logic Layer]
        CoreEngineLayer
    end

    subgraph 工具层 [Tooling Layers]
        ProcessingLayer
        AnalysisLayer
        StorageInterface
        FileStorage
    end

    EntryPoint --> CLILayer
    EntryPoint --> CoreEngineLayer
    EntryPoint -- 实例化并注入 --> StorageInterface
```

**说明:** 应用入口(`cli.py`)负责组装和启动。UI层(当前为CLI)负责用户交互，并调用核心引擎。核心引擎负责编排处理层、分析层完成核心业务逻辑，并通过`StorageInterface`与具体的存储实现（当前为`FileStorage`，它为每个文件ID管理独立的JSON文件）进行数据的持久化与读取。处理层和分析层不直接与存储层交互，它们从核心引擎接收数据（主要是DTOs），完成处理或分析后将结果返回给核心引擎。数据在各组件间主要以数据传输对象(DTOs)的形式传递。各层之间通过定义的接口（Python类和方法）交互。

- **3.2 组件职责 (Component Breakdown):**
    
    - **应用入口 (`cli.py`):** 启动应用，解析命令行参数，配置日志，实例化并组装存储（`FileStorage`作为`StorageInterface`的实现）、引擎、UI层。
    - **UI层 (`ui.cli_interface.CliInterface`):** 持有引擎实例，实现命令行菜单、用户输入处理、调用引擎执行操作、展示结果、处理配置。_(未来可替换为GUI层)_
    - **核心引擎层 (`core.engine.KnowledgeDistillerEngine`):** 应用核心，独立于UI。管理核心状态（如分析结果摘要、待审核项）；实例化并持有分析器(`MD5Analyzer`, `SemanticAnalyzer`)及处理工具(`BlockMerger`)；编排`run_analysis()`流程（调用Processing -> 将`unstructured`元素转换为内部`BlockDTO` -> 调用`BlockMerger` -> Analysis -> 内部状态更新）；提供数据加载/保存接口（通过`StorageInterface`调用）；实现`apply_decisions()`生成输出文件；提供供UI调用的公共接口。**与存储层通过`StorageInterface`解耦。**
    - **分析工具层 (`analysis/` - `MD5Analyzer`, `SemanticAnalyzer`):** 封装具体的分析算法。接收`BlockDTO`列表等数据输入，执行计算（MD5, 语义相似度），返回分析结果。内部处理模型加载（如`SemanticAnalyzer.load_model()`）。**已优化为跳过标题块**。
    - **处理工具层 (`processing/` - `document_processor.py`, `block_merger.py`):**
        - `document_processor`: 使用`unstructured`将文档转换为`unstructured`的元素对象列表。
        -  block_merger: 负责将从 BlockDTO 列表中识别出的连续代码块（相同语言）合并成单个 BlockDTO，并在其 metadata 中记录语言标识（如 "language": "python"）。合并后的块将标记原块为 DELETE 状态并关联新块 ID。当前实现完全适配 DTO 架构，需通过测试验证多语言和嵌套代码的合并效果。
    - **存储接口 (`storage/storage_interface.py` - `StorageInterface`):** 定义了存储层应提供的标准操作接口，如文件注册、块数据的保存与加载、决策的保存与加载等。
    - **存储层 (`storage/file_storage.py` - `FileStorage`):** `StorageInterface`的具体实现。**通过为每个`file_id`读写独立的JSON文件（例如 `file_metadata.json` 存储文件元数据，`blocks_{file_id}.json`存储该文件的`BlockDTO`列表，`decisions_{file_id}.json` 存储该文件的用户决策列表，`results_{file_id}_{analysis_type}.json` 存储分析结果）来持久化数据。** 封装了文件路径处理和JSON序列化/反序列化逻辑。_(未来可替换为数据库实现)_
- **3.3 各层职责细化**
    
    1. **`cli.py`:** (同v1.1)
    2. **`ui/cli_interface.py` (`CliInterface` 类):** (同v1.1)
    3. **`core/engine.py` (`KnowledgeDistillerEngine` 类):**
        - 实现 `run_analysis()`，按顺序调用：
            - `processing.document_processor.process_file()` (针对单个文件) 获取`unstructured`元素。
            - 内部逻辑将`unstructured`元素转换为`BlockDTO`列表，并为每个`BlockDTO`分配文件ID。
            - 调用`self.storage.save_block_dtos(file_id, block_dtos)`持久化初始块数据。
            - 调用 self.block_merger.merge_code_blocks(block_dtos) 合并代码块。若合并失败（如异常或配置跳过），引擎记录警告并继续使用原始块，不影响后续流程。
            - `_load_and_apply_existing_decisions()` (从`self.storage.load_decisions_for_file(file_id)`加载决策并更新`BlockDTO`的`kd_processing_status`)。
            - `analysis.md5_analyzer.find_duplicates()` (接收`BlockDTO`列表，返回结果)。
            - `_apply_md5_decisions()` (根据 MD5 结果更新`BlockDTO`的`kd_processing_status`，并通过`self.storage.save_decisions_for_file`持久化新决策)。
            - `analysis.semantic_analyzer.load_model()`。
            - `analysis.semantic_analyzer.find_similar_pairs()` (接收`BlockDTO`列表，返回结果)。
            - 分析结果通过 `self.storage.save_analysis_results(file_id, type, results)` 持久化。
        - BlockDTO 关键字段
            | 字段 | 类型 | 描述 |
            |------|------|------|
            | block_id | str | 内容块的唯一ID（通常为MD5哈希） |
            | kd_processing_status | DecisionType | 决策状态：KEEP/DELETE/UNDECIDED |
            | metadata | Dict[str, Any] | 原始解析信息（如 element_id, parent_id） |
            | duplicate_of_block_id | Optional[str] | 指向重复源块的ID |
            | analysis_text | str | 标准化后的分析文本（去除非内容字符） |
    4. **`analysis/` (`MD5Analyzer`, `SemanticAnalyzer` 类):** 
        run_analysis() 流程细节
        | 步骤 | 关键操作 | 输出 |
        |------|----------|------|
        | 1. 文档处理 | 调用 document_processor.process_directory()，转换为 BlockDTO | blocks_data 列表 |
        | 2. 代码块合并 | 调用 block_merger.merge_code_blocks()（当前跳过有效合并） | 修改后的 blocks_data |
        | 3. 决策初始化 | 从存储加载或初始化默认决策 | block_decisions 字典 |
        | 4. MD5去重 | 调用 MD5Analyzer.find_md5_duplicates() | md5_duplicates 列表 |
        | 5. 语义分析 | 加载模型并调用 SemanticAnalyzer.find_similar_pairs() | semantic_duplicates 列表 |
        | 6. 结果保存 | 通过 StorageInterface 保存分析结果 | 更新存储层的JSON文件 |

    5. **`processing/` (`document_processor.py`, `block_merger.py`):**
        - `document_processor.py`: (同v1.1)
        - `block_merger.py`: **其目标是将代码块合并。当前实现已使用DTOs (`BlockDTO`, `CodeBlockDTO`)。其合并逻辑的有效性和在引擎中的集成效果是后续优化的重点。**
    6. **`storage/storage_interface.py` (`StorageInterface`):** (同v1.1，接口定义基本吻合实际)
    7. **`storage/file_storage.py` (`FileStorage` 类):**
        - 实现 `StorageInterface`。
        - **管理多个基于`file_id`的JSON文件：**
            - `file_metadata.json`: (全局) 存储所有已处理文件的元数据 (`FileDTO`s 字典)。
            - `blocks_{file_id}.json`: 存储特定文件的 `BlockDTO`s 列表。
            - `results_{file_id}_{analysis_type}.json`: 存储特定文件特定分析类型的原始结果。
            - `decisions_{file_id}.json`: 存储特定文件的用户决策列表 (`DecisionDTO`s)。
        - 封装 JSON 文件的读写和路径处理。
    

**4. 技术栈选型 (Technology Stack)** (同v1.1)

**5. 数据模型 (Data Model)**

- **5.1 核心数据结构 (主要为DTOs - `core/models.py`):** (大部分同v1.1)
    - **`BlockDTO`**: ... `embedding: Optional[List[float]] = Field(default=None, exclude=True)` ... **`kd_processing_status` (`DecisionType` Enum) 会在运行时根据从存储加载的`DecisionDTO`进行更新。**
    - **`DecisionDTO`**: (新增或明确) 代表一个持久化的决策单元。属性：`decision_id` (PK), `file_id` (FK), `block_id` (FK, 针对哪个块的决策), `decision_type` (`DecisionType`), `duplicate_of_block_id` (Optional FK), `timestamp`。
    新增字段说明
    | 字段 | 类型 | 描述 |
    |------|------|------|
    | metadata.language | Optional[str] | 仅代码块有效，由 block_merger 写入语言标识（如 python）。 |
- **5.2 存储层数据结构 (`FileStorage` - JSON文件):**
    - **`file_metadata.json`**: 存储 `FileDTO` 对象的字典 (key: filepath_str)。
    - **`blocks_{file_id}.json`**: 存储特定 `file_id` 的 `BlockDTO` 对象列表。这些DTO中的`kd_processing_status`反映了加载决策并应用后的状态。
    - **`results_{file_id}_{analysis_type}.json`**: 存储特定 `file_id` 和分析类型的原始分析结果。
    - **`decisions_{file_id}.json`**: **存储特定 `file_id` 的 `DecisionDTO` 对象列表，这是用户决策的主要持久化形式。**
    - _(注：这些JSON文件的具体结构和内容由`FileStorage`实现决定，目标是为未来迁移到SQLite数据库模式做准备。)_
    - **SQLite (Phase 2/3 规划) - 初步设计将基于当前的DTO结构:** (同v1.1，但`Decisions`表会更明确对应`DecisionDTO`)
**6. 核心工作流程 (Core Workflows)**

- **6.1 文档处理与分析流程:**

```python
def run_analysis(self) -> bool:
    # 1. 文档处理 (_process_documents)
    # 2. 代码块合并 (_merge_code_blocks_step)
    # 3. 决策加载/初始化 (load_decisions + _initialize_decisions)
    # 4. MD5去重 (md5_analyzer.find_md5_duplicates)
    # 5. 语义分析 (semantic_analyzer.load_model + find_similar_pairs)
    # 6. 结果保存 (通过存储接口)
```

```mermaid
participant User
    participant CLI
    participant Engine
    participant DocProcessor as Processor
    participant BlkMerger as Merger
    participant AnalyzerMD5
    participant AnalyzerSem
    participant Storage as StorageInterface
    participant FileStore as FileStorage (per-file JSONs)

    User->>CLI: Run Analysis (dir/file)
    CLI->>Engine: run_analysis(path)
    Engine->>Processor: process_file(file_path)
    Processor-->>Engine: unstructured_elements_list
    Engine->>Engine: Convert elements to BlockDTOs, assign file_id
    Engine->>Storage: save_block_dtos(file_id, block_dtos)
    Storage->>FileStore: Write to blocks_{file_id}.json, file_metadata.json
    Engine->>Merger: merge_code_blocks(block_dtos)
    Note right of Merger: 合并失败时保留原块<br>并记录警告
    Merger-->>Engine: 返回合并后/原始 blocks
    Engine->>Storage: load_decisions_for_file(file_id)
    Storage-->>Engine: existing_decision_dtos
    Engine->>Engine: Apply existing_decision_dtos to BlockDTOs' kd_processing_status
    Engine->>AnalyzerMD5: find_duplicates(active_block_dtos, config)
    AnalyzerMD5-->>Engine: md5_duplicates_result
    Engine->>Engine: _apply_md5_decisions(md5_results, block_dict) # Updates DTOs' status
    Engine->>Storage: save_decisions_for_file(file_id, new_or_updated_decision_dtos_from_md5) # Persist MD5 decisions
    Engine->>AnalyzerSem: load_model()
    Engine->>AnalyzerSem: find_similar_pairs(active_block_dtos_for_semantic, config)
    AnalyzerSem-->>Engine: semantic_duplicates_result
    Engine->>Storage: save_analysis_results(file_id, "semantic", semantic_duplicates_result) # To results_{file_id}_semantic.json
    Engine-->>CLI: Analysis Complete Summary
    CLI-->>User: Display Summary/Results

```

6.2 决策应用流程:

```mermaid

participant User
    participant CLI
    participant Engine
    participant Storage as StorageInterface
    participant FileStore as FileStorage (per-file JSONs)

    User->>CLI: Review Duplicates/Similarities
    CLI->>Engine: get_md5_duplicates_for_review() / get_semantic_duplicates_for_review()
    Engine-->>CLI: pairs_to_review (derived from BlockDTOs and analysis results)
    CLI-->>User: Display Pairs
    User->>CLI: Make Decision (e.g., keep_1 for pair X, affecting block_id_Y)
    CLI->>Engine: update_block_decision(file_id, block_id_Y, new_decision_status, [optional_duplicate_of_id])
    Engine->>Storage: save_decisions_for_file(file_id, updated_decision_dtos) # Persists the new decision
    Storage->>FileStore: Update decisions_{file_id}.json
    User->>CLI: Apply Decisions (Generate dedup file)
    CLI->>Engine: apply_decisions()
    Engine->>Storage: load_all_block_dtos_across_files()
    Storage-->>Engine: all_block_dtos_from_all_files
    Engine->>Engine: For each file, load its decisions from decisions_{file_id}.json and apply to corresponding DTOs
    Engine->>Engine: Generate Output Content based on BlockDTOs and their kd_processing_status
    Engine-->>CLI: Output file generated
    CLI-->>User: Confirmation message

```

7.风险与缓解 (Risks & Mitigation)**

- 大文件处理性能：document_processor 可能成为瓶颈，建议在Phase 3中优化分块逻辑
- **`BlockMerger` 功能验证**
    - 已确认：代码完全适配 DTO 架构，基础合并逻辑通过单元测试（见测试用例 test_fragmented_code_block_merge）。
    - 待验证：复杂场景（如多语言混合、嵌套代码）的合并效果，需补充集成测试。"
    
8.**短期任务 (Immediate Focus):**

1. **【首要】审查与优化 `BlockMerger`:**
    - **审查并优化 `processing.block_merger.py` 中的代码块合并逻辑。确保其能有效处理 `BlockDTO` 对象列表，正确生成合并后的 `BlockDTO` 或 `CodeBlockDTO`，并验证其在核心引擎中的集成和调用是正确且有效的。**
    - 为其补充单元测试和集成测试。
2. **代码清理与完善:** (同v1.1)
3. **测试增强:**
    - (同v1.1)
    - **为 `FileStorage` 针对按文件ID分离的JSON文件（`blocks_{file_id}.json`, `decisions_{file_id}.json`等）的交互逻辑增加更全面的单元测试。**
4. **配置管理优化:** (同v1.1)

