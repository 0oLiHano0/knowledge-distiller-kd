# 知识蒸馏工具（KD_Tool）

## 统一架构设计文档 · 蓝本 v2.1

> **发布日期** 2025‑05‑07 | **维护人** AI Tech Lead（Gemini）

---

### 1 概述 (Overview)

**1.1 设计目标** – 构建一款完全本地化的源信息治理工具，为个人与企业在导入知识库 / RAG 之前提供**文件级→内容级多层去重、冲突检测与精细管理**；通过分阶段演进保证高可维护性与商业可行性。

**1.2 设计范围** – 本文档描述截至 Phase 3 启动时的完整架构，并给出 Phase 3 (MVP) 与未来 Phase 4‑E（Enterprise 扩展）的演进路线。内容涵盖：
* 现有分层架构回顾（CLI + Engine + Processing + Analysis）。
* Phase 3 (MVP) 核心增强：
    * **文件级预过滤**：引入 `CzkawkaAdapter`（捆绑分发Czkawka CLI），实现精确重复文件过滤，结果写入SQLite。Engine具备在需要时自动触发扫描的能力。
    * **内容级去重增强**：新增 `SimHashAnalyzer`（使用`1e0ng/simhash` MIT许可库），形成 MD5 → SimHash → SBERT 的三层去重与候选池筛选逻辑。
    * **存储层升级**：直接采用 **SQLite** 作为核心数据存储，取代原FileStorage的JSON文件作为主存储方案。保留将数据导出为JSON的能力，用于调试和查错。
    * **`BlockMerger` 高优先级改进**：在Phase 3期间，并行投入资源提升其准确性和健壮性。
* **用户交互 (Phase 3 CLI)**：初期保持简洁，保障核心流程，后续迭代优化。
* 预留 **OCR / 多媒体去重 / LLM 辅助** 插件接口，用于 Phase 4-E。
* **AI Tech Lead 职责**：负责Czkawka CLI交互健壮性设计、SimHashAnalyzer工作流与决策管理细节设计、SQLite数据库详细设计、以及`BlockMerger`改进优先级的持续评估与推进。

---

### 2 设计原则与约束

| 类别   | 细则                                                                                         |
| ---- | ------------------------------------------------------------------------------------------ |
| 核心原则 | 本地离线优先 · 模块化 · 分阶段引入复杂技术 · 面向非技术用户（未来GUI）· 资源效率                                                  |
| 约束   | • 部署形态：桌面 / 轻量服务器 • 数据不出本地 • LLM 仅 Phase 4 及以后、本地 model • 主体代码保持 MIT/Apache 许可，GPL 组件仅插件调用 • **Czkawka CLI 将与应用捆绑分发** |

---

### 3 总体架构图

```mermaid
flowchart TB
  subgraph PreFilter[文件级预过滤 (Czkawka)]
    A[CzkawkaAdapter] -->|扫描结果| D2[Storage Layer: SQLite - duplicate_files table]
  end

  subgraph Ingest[内容摄取]
    D2 --唯一文件列表--> B0[Engine: 获取待处理文件]
    B0 --> B1[unstructured.partition_auto]
    B1 --> B2[ContentBlock Mapper + BlockMerger]
    B2 --> |BlockDTOs| D2[Storage Layer: SQLite - blocks table]
  end

  subgraph Dedup[内容级去重/检测 (三层过滤)]
    D2 --读取BlockDTOs--> C0[Engine: 编排分析]
    C0 --> C1[MD5Analyzer]
    C1 --精确重复结果--> D2[Storage Layer: SQLite - decisions/analyses table]
    C1 --剩余BlockDTOs--> C2[SimHashAnalyzer]
    C2 --近似重复结果/SBERT候选池--> D2[Storage Layer: SQLite - decisions/analyses table]
    C2 --SBERT候选池--> C3[SemanticAnalyzer (SBERT)]
    C3 --语义相似结果--> D2[Storage Layer: SQLite - decisions/analyses table]
  end

  subgraph Decision[决策 & 应用]
    D1[DecisionManager] -->|加载/保存决策| D2[Storage Layer: SQLite - decisions table]
    D1 --> |生成待审核列表| UI[User Interface CLI/GUI]
    UI --> D1
  end

  PreFilter --> Ingest
  Ingest --> Dedup
  Dedup --> Decision

  style D2 fill:#lightgrey,stroke:#333,stroke-width:2px
```

* **文件级预过滤**：`CzkawkaAdapter` 调用捆绑的 *Czkawka* CLI，扫描结果（重复文件信息）直接写入 SQLite 的 `duplicate_files` 表。Engine 根据此表获取唯一文件列表进行后续处理。Engine在需要时（如目标目录未扫描或数据陈旧）可自动触发此扫描。
* **内容摄取与处理**：对唯一文件列表进行解析 (`unstructured`)、转换为 `BlockDTO`、并由持续改进的 `BlockMerger` 进行代码块等合并处理，结果存入 SQLite 的 `blocks` 表。
* **内容级三层去重/检测**：
    1.  **MD5Analyzer**：处理所有未被先前决策排除的块，识别精确重复。精确重复的块将被标记，不再参与后续SimHash/SBERT分析。
    2.  **SimHashAnalyzer** (`1e0ng/simhash`库)：仅处理经MD5过滤后仍为 `KEEP/UNDECIDED` 状态的块。计算64-bit指纹，海明距离≤阈值的块对结果写入`analyses`表，并形成"SBERT候选池"。若CLI配置SimHash为终止层，则可直接基于此结果更新决策。
    3.  **SemanticAnalyzer (SBERT)**：**仅对SimHash生成的"SBERT候选池"** 进行语义嵌入及相似度计算，用于最终的精细判别或冲突检测。
* **决策与存储**：所有分析结果和用户决策均通过 `DecisionManager` 统一管理并持久化到 SQLite 的 `decisions` 和 `analyses` 表。`FileStorage`的角色转变为提供按需的JSON导出功能，用于调试和数据检查，不再作为主要数据存储。

---

### 4 关键组件职责

| 层        | 主要模块                                                                                  | 职责摘要                                                                                                                               |
| -------- | ------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| **入口** | `cli.py`                                                                              | 启动、解析参数、装配依赖、调用 CLI/UI                                                                                                        |
| **UI** | `ui.cli_interface.CliInterface` (现) → `ui.gui.GuiInterface` (Phase 4)                 | 用户交互；命令/事件派发；结果展示。**Phase 3 CLI初期保持简洁，保障核心流程，后续迭代优化。** |
| **核心引擎** | `core.KnowledgeDistillerEngine`                                                       | 编排全流程；维护状态；统一调用预过滤/处理/分析；管理分析器链式逻辑 (MD5→SimHash→SBERT)；**在需要时自动触发Czkawka文件扫描**；异常与事务管理。                |
| **预过滤** | `prefilter.CzkawkaAdapter` *(新)* | 执行捆绑的Czkawka CLI扫描，解析其`--json`输出，将重复文件信息写入SQLite的`duplicate_files`表。**CLI交互的健壮性由AI Tech Lead设计。** |
| **处理层** | `processing.document_processor` + `processing.block_merger`                           | 文档解析→BlockDTO；代码块合并。**`BlockMerger`的准确性和健壮性作为高优先级持续改进，与Phase 3其他功能并行开发，重点扩展测试用例并优化逻辑。** |
| **分析层** | `analysis.MD5Analyzer`, `analysis.SimHashAnalyzer` (新), `analysis.SemanticAnalyzer`   | **三层去重+冲突检测**：MD5精确去重；SimHash (`1e0ng/simhash`库)进行近似去重并为SBERT提供候选池；SBERT (MiniLM模型)对候选池进行语义精排。**SimHash工作流与决策管理细节由AI Tech Lead设计。** |
| **决策管理** | `decision.DecisionManager`                                                            | 汇总分析结果（MD5, SimHash, SBERT）；加载/保存DecisionDTO到SQLite；生成待审核列表。                                                              |
| **存储层** | `storage.StorageInterface` → `storage.SqliteStorage` (新增)                             | **以SQLite为唯一核心数据存储**。提供DTO的CRUD操作；事务与索引管理（详细设计由AI Tech Lead负责）。不再进行JSON双写，旧`FileStorage`可改造为提供JSON导出功能。 |

---

### 5 技术栈与依赖

* **Python 3.11** | Poetry | Pytest + Coverage | Black / isort / mypy
* **文档解析**：unstructured 0.13+ (Apache‑2.0)
* **文件去重**：Czkawka 6.x (MIT) – **捆绑CLI与应用一同分发**
* **NLP (语义分析)**：SentenceTransformers + MiniLM (`all‑MiniLM‑L6‑v2`)
* **SimHash**：`simhash` (by 1e0ng, MIT License) – Python Simhash实现
* **数据库**：SQLite 3 (Phase 3核心存储)；PostgreSQL (Phase E 备选)
* **GUI 预选**：Tkinter (轻量) → PySide (Phase 4 可评估)

---

### 6 数据模型与存储演进

| 表 / 功能         | Phase 3 (SQLite - 核心存储)                                    | 说明                                                                      |
| ---------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------- |
| `documents`      | path (PK), file_hash, type, size, ctime, mtime, ingest_time, status | 存储已扫描/处理的文件元数据，status可反映是否为Czkawka识别的重复文件等。         |
| `blocks`         | block_id (PK), file_id (FK to documents), content_hash (MD5), simhash (Optional), text, raw_element_type, kd_processing_status, page_no, prev_block_id, next_block_id, merged_into_id (Optional FK), analysis_text, metadata (JSON) | 存储内容块信息，包括其处理状态、各类指纹、原始元素信息及自定义元数据。            |
| `analyses`       | analysis_id (PK), block_id_A (FK to blocks), block_id_B (Optional FK to blocks), analysis_type (MD5, SimHash, SBERT), score (Optional), details (JSON) | 存储各分析阶段产生的对比结果或标记信息。                                    |
| `decisions`      | decision_id (PK), file_id (FK to documents), block_id (FK to blocks), decision_type, duplicate_of_block_id (Optional FK to blocks), user_id (Optional), timestamp, comment (Optional), source (User, MD5, SimHash_Auto) | 存储用户或系统自动做出的决策。                                                |
| `duplicate_files`| group_id, file_path (FK to documents.path - conceptual), is_original | 存储Czkawka扫描出的文件级重复组信息。                                         |
| **JSON导出** | 按需从SQLite导出为JSON文件                                         | 用于调试、数据检查或特定场景的备份，不再作为实时数据存储。                       |

> **存储策略**：Phase 3直接使用SQLite作为核心数据存储。不再进行JSON文件的实时写入或作为主要数据源。提供从SQLite导出数据到JSON格式的功能。

---

### 7 核心流程

1.  **文件级扫描 (`kd scan-files <dir>` 或由Engine自动触发)**
    * `Engine` 调用 `CzkawkaAdapter`。
    * `CzkawkaAdapter` 执行捆绑的 Czkawka CLI，解析其JSON输出。
    * 结果（重复文件组信息）写入 SQLite 的 `duplicate_files` 表，并可能更新 `documents` 表中文件的状态。
    * 流程返回唯一文件列表（或标记哪些文件可被后续流程忽略）。

2.  **内容摄取与初始处理 (`kd ingest <file_or_dir_after_scan>`)**
    * `Engine` 获取（来自Czkawka结果的）唯一有效文件列表。
    * 对每个文件：调用 `document_processor` (`unstructured`) 解析。
    * 转换为 `BlockDTO` 对象列表。
    * 调用 `BlockMerger`（高优先级改进中）合并代码块等。
    * 将处理后的 `BlockDTO`s 存入 SQLite 的 `blocks` 表。

3.  **去重与分析 (`kd dedup`)**
    * `Engine` 从 SQLite 加载需要分析的 `BlockDTO`s。
    * **MD5Analyzer**：计算MD5，识别精确重复块。结果及自动决策写入 `analyses`/`decisions` 表。被标记为精确重复的块不再参与后续SimHash/SBERT。
    * **SimHashAnalyzer**：对剩余块计算SimHash指纹。
        * 利用 `SimhashIndex` 高效查找海明距离≤阈值的近似重复对。
        * 结果写入 `analyses` 表。
        * 符合条件的对构成"SBERT候选池"。
        * 若配置为终止层，可直接更新 `decisions` 表。
    * **SemanticAnalyzer (SBERT)**：仅加载并处理"SBERT候选池"中的块对。
        * 计算语义相似度。
        * 结果写入 `analyses` 表，供用户审核或进一步自动处理。
    * `DecisionManager` 汇总所有分析结果，准备待审核项。

4.  **用户审核**（CLI / 未来 GUI）
    * UI层调用 `DecisionManager` 获取待审核的相似对列表（来自MD5, SimHash, SBERT的综合结果）。
    * 用户做出决策（保留、删除、标记等）。
    * 用户决策通过 `DecisionManager` 存入 SQLite 的 `decisions` 表。

5.  **应用决策 (`kd apply`)**
    * `Engine` 加载所有相关的 `BlockDTO`s 及其最终决策状态（来自 `decisions` 表）。
    * 根据决策状态（KEEP, DELETE等）重新组织内容。
    * 生成去重后的输出文件 (如 `_deduped.{ext}`)。

---

### 8 里程碑 (时间灵活，质量优先)

| 阶段产出                     | 主要负责人       | 备注                                                           |
| -------------------------- | ------------- | -------------------------------------------------------------- |
| CzkawkaAdapter 实现与单元测试  | Coding AI     | 包含CLI捆绑、执行与结果入库SQLite (`duplicate_files`)              |
| SimHashAnalyzer 实现与单元测试 | Coding AI     | 使用 `1e0ng/simhash`，实现指纹计算、候选池生成                     |
| SQLite Schema 定义与核心存储逻辑 | Coding AI     | `SqliteStorage` 实现各表的CRUD，事务管理 (详细设计由Tech Lead负责) |
| BlockMerger 初步改进与测试   | Coding AI     | 根据Tech Lead的优先级评估和新增用例进行第一轮优化                   |
| **Phase 3 MVP 集成测试通过 & 报告** | **Tech Lead** | **确保上述组件协同工作，核心流程跑通，输出符合预期** |
| GUI α 版启动 (Phase 4 规划)   | —             |                                                                |

---

### 9 风险与缓解

| 风险                                   | 等级 | 缓解措施                                                                                                                 |
| ------------------------------------ | -- | ---------------------------------------------------------------------------------------------------------------------- |
| **`BlockMerger` 合并不准确/不全面** | **高** | **高优先级持续改进**：Tech Lead主导重新评估并推进；Coding AI投入专门精力；全面扩展单元/回归测试；保留 `--skip-merge` CLI参数作为临时规避。 |
| Czkawka CLI 交互不稳定/错误处理不足       | 中  | Tech Lead 负责设计详细的错误处理、超时、重试（若适用）机制；充分测试不同场景下的CLI调用。                                                       |
| SBERT 内存/性能开销（即使有候选池）         | 中  | 坚持使用MiniLM；确保SimHash有效缩减候选池；未来可探索更细致的批处理、动态加载/卸载模型、或更轻量级语义模型。                                           |
| SimHash 阈值选择与效果不佳              | 中  | 提供可配置的SimHash距离阈值；通过测试和用户反馈调整默认值；清晰展示SimHash结果供用户判断。                                                      |
| GPL 等限制性许可证的间接引入风险           | 中  | 严格审查新增依赖（如`simhash`库已确认为MIT）；未来插件化功能（如OCR）若使用GPL组件，确保其在独立进程中运行，通过清晰接口与主程序隔离。                 |
| SQLite 性能瓶颈（大规模数据）          | 低-中 | Tech Lead 负责详细的Schema设计（含索引）；优化查询语句；启用WAL模式；未来若极端情况，可考虑迁移至更大型数据库（如PostgreSQL）。                        |
| 初期CLI用户体验对非技术用户不够友好       | 中  | Phase 3 MVP阶段接受此点，优先保障核心逻辑。后续迭代中，根据用户反馈逐步优化CLI交互，或在Phase 4通过GUI改善。                                        |

---

### 10 附录

A.  **BlockMerger 测试用例清单**（建议在 `tests/test_block_merger.py` 中持续扩充和文档化关键场景）
B.  **OCR 插件接口草案** (示例: `ocr_plugin.run(file_path: str, config: dict) -> List[BlockDTO]`)
C.  **图片去重扩展方案** (可调研 `imagehash` (pHash/dHash/aHash, MIT/BSD类许可) 或 Czkawka 内置的相似图片查找功能作为预过滤扩展)
D.  **CzkawkaAdapter 错误处理设计要点** (由Tech Lead后续补充)
E.  **SimHashAnalyzer 工作流与决策逻辑设计要点** (由Tech Lead后续补充)
F.  **SQLite Schema 详细设计文档** (由Tech Lead后续补充或指导Coding AI完成)

---
